{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Урок 2. Профилирование пользователей. Сегментация: unsupervised learning (clustering, LDA/ARTM), supervised (multi/binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наши новости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Заместитель председателяnправительства РФnСерг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4896</td>\n",
       "      <td>Матч 1/16 финала Кубка России по футболу был п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4897</td>\n",
       "      <td>Форвард «Авангарда» Томаш Заборский прокоммент...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                              title\n",
       "0       6  Заместитель председателяnправительства РФnСерг...\n",
       "1    4896  Матч 1/16 финала Кубка России по футболу был п...\n",
       "2    4897  Форвард «Авангарда» Томаш Заборский прокоммент..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv(\"articles.csv\")\n",
    "print(news.shape)\n",
    "news.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим пользователей и списки последних прочитанных новостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>u105138</td>\n",
       "      <td>[293672, 293328, 293001, 293622, 293126, 1852]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>u108690</td>\n",
       "      <td>[3405, 1739, 2972, 1158, 1599, 322665]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>u108339</td>\n",
       "      <td>[1845, 2009, 2356, 1424, 2939, 323389]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                        articles\n",
       "0  u105138  [293672, 293328, 293001, 293622, 293126, 1852]\n",
       "1  u108690          [3405, 1739, 2972, 1158, 1599, 322665]\n",
       "2  u108339          [1845, 2009, 2356, 1424, 2939, 323389]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv(\"users_articles.csv\")\n",
    "users.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, нам нужно получить векторные представления пользователей на основе прочитанным ими новостей и самих новостей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Получаем векторные представления новостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\user\\anaconda3\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (1.16.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied: Cython==0.29.14 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (0.29.14)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2019.9.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: razdel in c:\\users\\user\\anaconda3\\lib\\site-packages (0.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\users\\user\\anaconda3\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pymorphy2) (0.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\users\\user\\anaconda3\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pymorphy2) (0.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#предобработка текстов\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import word_tokenize\n",
    "\n",
    "from razdel import tokenize # https://github.com/natasha/razdel\n",
    "#!pip install razdel\n",
    "\n",
    "import pymorphy2  # pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_ru = stopwords.words('russian')\n",
    "len(stopword_ru)\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('stopwords.txt') as f:\n",
    "    additional_stopwords = [w.strip() for w in f.readlines() if w]\n",
    "stopword_ru += additional_stopwords\n",
    "len(stopword_ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убирем из текста латиницу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    очистка текста\n",
    "    \n",
    "    на выходе очищеный текст\n",
    "    \n",
    "    '''\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
    "    text = re.sub(\"[A-z]\", '', text) # убираем из текста латиницу\n",
    "    #tokens = list(tokenize(text))\n",
    "    #words = [_.text for _ in tokens]\n",
    "    #words = [w for w in words if w not in stopword_ru]\n",
    "    \n",
    "    #return \" \".join(words)\n",
    "    return text\n",
    "\n",
    "cache = {}\n",
    "\n",
    "def lemmatization(text):\n",
    "    '''\n",
    "    лемматизация\n",
    "        [0] если зашел тип не `str` делаем его `str`\n",
    "        [1] токенизация предложения через razdel\n",
    "        [2] проверка есть ли в начале слова '-'\n",
    "        [3] проверка токена с одного символа\n",
    "        [4] проверка есть ли данное слово в кэше\n",
    "        [5] лемматизация слова\n",
    "        [6] проверка на стоп-слова\n",
    "\n",
    "    на выходе лист отлемматизированых токенов\n",
    "    '''\n",
    "\n",
    "    # [0]\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # [1]\n",
    "    tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    words_lem = []\n",
    "    for w in words:\n",
    "        if w[0] == '-': # [2]\n",
    "            w = w[1:]\n",
    "        if len(w)>1: # [3]\n",
    "            if w in cache: # [4]\n",
    "                words_lem.append(cache[w])\n",
    "            else: # [5]\n",
    "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cach)\n",
    "    \n",
    "    words_lem_without_stopwords=[i for i in words_lem if not i in stopword_ru] # [6]\n",
    "    \n",
    "    return words_lem_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Possible nested set at position 39\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Запускаем очистку текста. Будет долго...\n",
    "news['title'] = news['title'].apply(lambda x: clean_text(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Запускаем лемматизацию текста. Будет очень долго...\n",
    "news['title'] = news['title'].apply(lambda x: lemmatization(x), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь в 3 строчки обучим нашу модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сформируем список наших текстов, разбив еще и на пробелы\n",
    "texts = [t for t in news['title'].values]\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что такое common_dictionary и как он выглядит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'директор'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_dictionary[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все просто - это словарь наших слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 56.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import LdaModel\n",
    "# Train the model on the corpus.\n",
    "lda = LdaModel(common_corpus, num_topics=25, id2word=common_dictionary)#, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "# Save model to disk.\n",
    "temp_file = datapath(\"model.lda\")\n",
    "lda.save(temp_file)\n",
    "\n",
    "# Load a potentially pretrained model from disk.\n",
    "lda = LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучили модель. Теперь 2 вопроса:\n",
    "\n",
    "1. как выглядят наши темы\n",
    "2. как получить для документа вектор значений (вероятности принадлежности каждой теме)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['форвард', 'авангард', 'томаш', 'заборский', 'прокомментировать', 'игра', 'свой', 'команда', 'матч', 'чемпионат', 'кхл', 'против', 'атлантам', 'провести', 'плохой', 'матч', 'нижний', 'новгород', 'против', 'торпедо', 'настраиваться', 'первый', 'минута', 'включиться', 'работа', 'сказать', 'заборский', 'получиться', 'забросить', 'быстрый', 'гол', 'задать', 'хороший', 'темп', 'поединок', 'мочь', 'играть', 'ещё', 'хороший', 'сторона', 'пять', 'очко', 'выезд', 'девять', 'это', 'хороший']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(5, 0.47291338), (10, 0.06699602), (13, 0.3918452), (14, 0.048488002)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new corpus, made of previously unseen documents.\n",
    "other_texts = [t for t in news['title'].iloc[:3]]\n",
    "other_corpus = [common_dictionary.doc2bow(text) for text in other_texts]\n",
    "\n",
    "unseen_doc = other_corpus[2]\n",
    "print(other_texts[2])\n",
    "lda[unseen_doc] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0: рекомендовать выдать депутат налоговый констатировать ндс подъём\n",
      "topic_1: компания население фестиваль производитель иск эффективность добавлять\n",
      "topic_2: год который это исследование человек мочь сша\n",
      "topic_3: ракета снижение вероятно употребление настаивать сон расширение\n",
      "topic_4: фонд полоса горизонт звёздный выручка корзина эндрю\n",
      "topic_5: планета космос топливо катастрофа первый экипаж дональд\n",
      "topic_6: годовой арабский приобретать вслед расширение тбилиси грузия\n",
      "topic_7: рейс продолжительность аэропорт соцсеть орден вдвое сочи\n",
      "topic_8: превысить фрагмент югра мак джонс оцепить запорожский\n",
      "topic_9: восток напомнить это всё активность подчеркнуть разместить\n",
      "topic_10: смерть температура взрыв рак который метод группа\n",
      "topic_11: газ путин граница продукция экипаж египет испытание\n",
      "topic_12: остаток осложнение тереза закрываться роджер квебек швейцарец\n",
      "topic_13: это год который свой мочь весь всё\n",
      "topic_14: вицепремьер белый снять задать направлять фунт сдача\n",
      "topic_15: год тыс млн который источник человек сотрудник\n",
      "topic_16: военный территория власть который участок торговый товар\n",
      "topic_17: погибнуть мозг пострадать район произойти автомобиль результат\n",
      "topic_18: проверка остров японский озеро лётчик япония ресторан\n",
      "topic_19: обращение пищевой кот калинин разобрать захватить ткачёв\n",
      "topic_20: замечать справа ребро риска новозеландский джереми винчи\n",
      "topic_21: терминал соль мешок маркетинг пулково осложнить березовский\n",
      "topic_22: тело штат жертва преступление конструкция ведение нож\n",
      "topic_23: год россия это который российский млрд президент\n",
      "topic_24: миссия космонавт предприниматель станция египетский минск израиль\n"
     ]
    }
   ],
   "source": [
    "x=lda.show_topics(num_topics=25, num_words=7,formatted=False)\n",
    "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
    "\n",
    "#Below Code Prints Only Words \n",
    "for topic,words in topics_words:\n",
    "    print(\"topic_{}: \".format(topic)+\" \".join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень неплохо - большинство тем вполне можно описать о чем они"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте напишем функцию, которая будет нам возвращать векторное представление новости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = news['title'].iloc[0]\n",
    "\n",
    "def get_lda_vector(text):\n",
    "    unseen_doc = common_dictionary.doc2bow(text)\n",
    "    lda_tuple = lda[unseen_doc]\n",
    "    not_null_topics = dict(zip([i[0] for i in lda_tuple], [i[1] for i in lda_tuple]))\n",
    "\n",
    "    output_vector = []\n",
    "    for i in range(25):\n",
    "        if i not in not_null_topics:\n",
    "            output_vector.append(0)\n",
    "        else:\n",
    "            output_vector.append(not_null_topics[i])\n",
    "    return np.array(output_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.859912</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077573</td>\n",
       "      <td>0.015813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4899</td>\n",
       "      <td>0.217223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.601904</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id   topic_0  topic_1   topic_2   topic_3  topic_4   topic_5  topic_6  \\\n",
       "0       6  0.000000      0.0  0.000000  0.000000      0.0  0.000000      0.0   \n",
       "1    4896  0.000000      0.0  0.000000  0.000000      0.0  0.000000      0.0   \n",
       "2    4897  0.000000      0.0  0.000000  0.000000      0.0  0.472904      0.0   \n",
       "3    4898  0.000000      0.0  0.077573  0.015813      0.0  0.326101      0.0   \n",
       "4    4899  0.217223      0.0  0.000000  0.000000      0.0  0.000000      0.0   \n",
       "\n",
       "    topic_7  topic_8  ...  topic_15  topic_16  topic_17  topic_18  topic_19  \\\n",
       "0  0.074752      0.0  ...       0.0       0.0       0.0  0.000000       0.0   \n",
       "1  0.000000      0.0  ...       0.0       0.0       0.0  0.000000       0.0   \n",
       "2  0.000000      0.0  ...       0.0       0.0       0.0  0.000000       0.0   \n",
       "3  0.000000      0.0  ...       0.0       0.0       0.0  0.014138       0.0   \n",
       "4  0.000000      0.0  ...       0.0       0.0       0.0  0.034129       0.0   \n",
       "\n",
       "   topic_20  topic_21  topic_22  topic_23  topic_24  \n",
       "0       0.0  0.000000       0.0  0.859912       0.0  \n",
       "1       0.0  0.000000       0.0  0.000000       0.0  \n",
       "2       0.0  0.000000       0.0  0.000000       0.0  \n",
       "3       0.0  0.026507       0.0  0.000000       0.0  \n",
       "4       0.0  0.000000       0.0  0.601904       0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_matrix = pd.DataFrame([get_lda_vector(text) for text in news['title'].values])\n",
    "topic_matrix.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "topic_matrix['doc_id'] = news['doc_id'].values\n",
    "topic_matrix = topic_matrix[['doc_id']+['topic_{}'.format(i) for i in range(25)]]\n",
    "topic_matrix.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прекрасно, мы получили вектора наших новостей! И даже умеем интерпретировать получившиеся темы.\n",
    "\n",
    "Можно двигаться далее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Следующий шаг - векторные представления пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>u105138</td>\n",
       "      <td>[293672, 293328, 293001, 293622, 293126, 1852]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>u108690</td>\n",
       "      <td>[3405, 1739, 2972, 1158, 1599, 322665]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>u108339</td>\n",
       "      <td>[1845, 2009, 2356, 1424, 2939, 323389]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                        articles\n",
       "0  u105138  [293672, 293328, 293001, 293622, 293126, 1852]\n",
       "1  u108690          [3405, 1739, 2972, 1158, 1599, 322665]\n",
       "2  u108339          [1845, 2009, 2356, 1424, 2939, 323389]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dict = dict(zip(topic_matrix['doc_id'].values, topic_matrix[['topic_{}'.format(i) for i in range(25)]].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03591073, 0.04665267, 0.20065923, 0.01906193, 0.01770151,\n",
       "       0.07549366, 0.        , 0.01628084, 0.        , 0.        ,\n",
       "       0.        , 0.07192532, 0.        , 0.50563312, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dict[293622]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_articles_list = users['articles'].iloc[33]\n",
    "\n",
    "def get_user_embedding(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.median(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.08594252, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.26163615, 0.        ,\n",
       "       0.01771302, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.23652121, 0.        ])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_embedding(user_articles_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересовался новостями с топиками topic_3, topic_14 (что-то про политику и государство)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#users['articles'].iloc[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\" \".join(news[news['doc_id']==323186]['title'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь получим эмбединги для всех пользователей и проверим их качество на конкретной downstream-задаче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>u105138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086359</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068538</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>u108690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013366</td>\n",
       "      <td>0.051668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185099</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>u108339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115907</td>\n",
       "      <td>0.078343</td>\n",
       "      <td>0.010194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022561</td>\n",
       "      <td>0.284186</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  topic_0   topic_1   topic_2   topic_3  topic_4   topic_5  topic_6  \\\n",
       "0  u105138      0.0  0.000000  0.086359  0.009531      0.0  0.000000      0.0   \n",
       "1  u108690      0.0  0.013366  0.051668  0.000000      0.0  0.005683      0.0   \n",
       "2  u108339      0.0  0.000000  0.107092  0.000000      0.0  0.029699      0.0   \n",
       "\n",
       "   topic_7  topic_8  ...  topic_15  topic_16  topic_17  topic_18  topic_19  \\\n",
       "0      0.0      0.0  ...  0.158143  0.000000  0.000000       0.0       0.0   \n",
       "1      0.0      0.0  ...  0.058213  0.000000  0.000000       0.0       0.0   \n",
       "2      0.0      0.0  ...  0.115907  0.078343  0.010194       0.0       0.0   \n",
       "\n",
       "   topic_20  topic_21  topic_22  topic_23  topic_24  \n",
       "0       0.0       0.0  0.000000  0.068538       0.0  \n",
       "1       0.0       0.0  0.000000  0.185099       0.0  \n",
       "2       0.0       0.0  0.022561  0.284186       0.0  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embeddings = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding(x), 1)])\n",
    "user_embeddings.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "user_embeddings['uid'] = users['uid'].values\n",
    "user_embeddings = user_embeddings[['uid']+['topic_{}'.format(i) for i in range(25)]]\n",
    "user_embeddings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет готов - можно попробовать обучить модель. Загрузим нашу разметку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>u107120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>u102277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>u102444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  churn\n",
       "0  u107120      0\n",
       "1  u102277      0\n",
       "2  u102444      0"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.read_csv(\"users_churn.csv\")\n",
    "target.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>u105138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086359</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>u108690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013366</td>\n",
       "      <td>0.051668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>u108339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078343</td>\n",
       "      <td>0.010194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022561</td>\n",
       "      <td>0.284186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  topic_0   topic_1   topic_2   topic_3  topic_4   topic_5  topic_6  \\\n",
       "0  u105138      0.0  0.000000  0.086359  0.009531      0.0  0.000000      0.0   \n",
       "1  u108690      0.0  0.013366  0.051668  0.000000      0.0  0.005683      0.0   \n",
       "2  u108339      0.0  0.000000  0.107092  0.000000      0.0  0.029699      0.0   \n",
       "\n",
       "   topic_7  topic_8  ...  topic_16  topic_17  topic_18  topic_19  topic_20  \\\n",
       "0      0.0      0.0  ...  0.000000  0.000000       0.0       0.0       0.0   \n",
       "1      0.0      0.0  ...  0.000000  0.000000       0.0       0.0       0.0   \n",
       "2      0.0      0.0  ...  0.078343  0.010194       0.0       0.0       0.0   \n",
       "\n",
       "   topic_21  topic_22  topic_23  topic_24  churn  \n",
       "0       0.0  0.000000  0.068538       0.0      0  \n",
       "1       0.0  0.000000  0.185099       0.0      1  \n",
       "2       0.0  0.022561  0.284186       0.0      1  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.merge(user_embeddings, target, 'left')\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделим данные на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[['topic_{}'.format(i) for i in range(25)]], \n",
    "                                                    X['churn'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "#обучим наш пайплайн\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11407111, 0.03882586, 0.50401099, 0.10187303, 0.02114451,\n",
       "       0.01324575, 0.10428638, 0.03273921, 0.03802632, 0.0899001 ])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#наши прогнозы для тестовой выборки\n",
    "preds = logreg.predict_proba(X_test)[:, 1]\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рассчитаем Precision, Recall, F_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "thresholds = thresholds[ix]\n",
    "fscore = fscore[ix],\n",
    "precision = precision[ix],\n",
    "recall = recall[ix]\n",
    "#print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        #fscore[ix],\n",
    "                                                                        #precision[ix],\n",
    "                                                                        #recall[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9430734345020059"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ras = roc_auc_score(y_test, preds)\n",
    "ras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Модифицировать код функции get_user_embedding таким образом, чтобы считалось не среднее (как в примере np.mean), а медиана. Применить такое преобразование к данным, обучить модель прогнозирования оттока и посчитать метрики качества и сохранить их: roc auc, precision/recall/f_score (для 3 последних - подобрать оптимальный порог с помощью precision_recall_curve, как это делалось на уроке)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding1(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.median(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings1 = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding1(x), 1)])\n",
    "user_embeddings1.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "user_embeddings1['uid'] = users['uid'].values\n",
    "user_embeddings1 = user_embeddings1[['uid']+['topic_{}'.format(i) for i in range(25)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.merge(user_embeddings1, target, 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[['topic_{}'.format(i) for i in range(25)]], \n",
    "                                                    X['churn'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "#обучим наш пайплайн\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11407111, 0.03882586, 0.50401099, 0.10187303, 0.02114451,\n",
       "       0.01324575, 0.10428638, 0.03273921, 0.03802632, 0.0899001 ])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#наши прогнозы для тестовой выборки\n",
    "preds = logreg.predict_proba(X_test)[:, 1]\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision1, recall1, thresholds1 = precision_recall_curve(y_test, preds)\n",
    "fscore1 = (2 * precision1 * recall1) / (precision1 + recall1)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore1)\n",
    "thresholds1 = thresholds1[ix]\n",
    "fscore1 = fscore1[ix],\n",
    "precision1 = precision1[ix],\n",
    "recall1 = recall1[ix]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9430734345020059"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ras1 = roc_auc_score(y_test, preds)\n",
    "ras1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. Повторить п.2, но используя уже не медиану, а max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding2(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.max(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings2 = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding2(x), 1)])\n",
    "user_embeddings2.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "user_embeddings2['uid'] = users['uid'].values\n",
    "user_embeddings2 = user_embeddings2[['uid']+['topic_{}'.format(i) for i in range(25)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.merge(user_embeddings2, target, 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[['topic_{}'.format(i) for i in range(25)]], \n",
    "                                                    X['churn'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "#обучим наш пайплайн\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13614938, 0.01653182, 0.58940701, 0.09122468, 0.0269179 ,\n",
       "       0.03563638, 0.23095348, 0.00158646, 0.02025753, 0.17842692])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#наши прогнозы для тестовой выборки\n",
    "preds = logreg.predict_proba(X_test)[:, 1]\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision2, recall2, thresholds2 = precision_recall_curve(y_test, preds)\n",
    "fscore2 = (2 * precision2 * recall2) / (precision2 + recall2)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore2)\n",
    "thresholds2 = thresholds2[ix]\n",
    "fscore2 = fscore2[ix],\n",
    "precision2 = precision2[ix],\n",
    "recall2 = recall2[ix]\n",
    "#print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds2[ix], \n",
    "                                                                        #fscore2[ix],\n",
    "                                                                        #precision2[ix],\n",
    "                                                                        #recall2[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9447363218791791"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ras2 = roc_auc_score(y_test, preds)\n",
    "ras2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ = [thresholds, precision, recall, fscore, ras]\n",
    "median_ = [thresholds1, precision1, recall1 ,fscore1, ras1]\n",
    "max_ = [thresholds2, precision2, recall2,fscore2, ras2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame({'mean': mean_,\n",
    "                        'median': median_,\n",
    "                        'max': max_}).T\n",
    "metrics.columns=['thresholds', 'precision', 'recall','fscore', 'roc_auc_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.246034</td>\n",
       "      <td>(0.5871559633027523,)</td>\n",
       "      <td>0.783673</td>\n",
       "      <td>(0.6713286713286712,)</td>\n",
       "      <td>0.943073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>median</td>\n",
       "      <td>0.246034</td>\n",
       "      <td>(0.5871559633027523,)</td>\n",
       "      <td>0.783673</td>\n",
       "      <td>(0.6713286713286712,)</td>\n",
       "      <td>0.943073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.34122</td>\n",
       "      <td>(0.7008547008547008,)</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>(0.6847599164926931,)</td>\n",
       "      <td>0.944736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       thresholds              precision    recall                 fscore  \\\n",
       "mean     0.246034  (0.5871559633027523,)  0.783673  (0.6713286713286712,)   \n",
       "median   0.246034  (0.5871559633027523,)  0.783673  (0.6713286713286712,)   \n",
       "max       0.34122  (0.7008547008547008,)  0.669388  (0.6847599164926931,)   \n",
       "\n",
       "       roc_auc_score  \n",
       "mean        0.943073  \n",
       "median      0.943073  \n",
       "max         0.944736  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
